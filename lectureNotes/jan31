
------- January 31 -------

Events
    Any collection of outcomes from the sample space
        A subset of the greater set
    Simple event
        Consists of one outcome
        E = {(1,1)}
    Compound event 
        More than one outcome
    Flipping a coin 3 times
        Sample space = 
            {
            (h,h,h),
            (h,h,t),
            (h,t,h),
            (t,h,h),
            (h,t,t),
            (t,h,t),
            (t,t,h),
            (t,t,t),
            }
        Events
            all heads = {(h,h,h)}
            more than one tails = {ttt,htt,tht,tth}
    Drink accuracy
        Weigh every cup
        Sample space = {0,V} V = volume of cup
        Events
              Empty cup = {0}
              Full cup = {V}
              underfilled = {0, 11}
              target = {11.4, 12.4}
   
AXIOMS of Probability
    Probability is a function that takes in a set and outputs numbers according to the
    following rules      
        let E and F be the sets in EcP(Set)
        let P:E (P is function, E is a set) -> R (real num)
        Where P satisfies:
            1) P(Sample Space) = 1
            2) For any event E, P(E) >= 0
            3) letE and F be mutually exclusive: EnF = 0
                P(EuF) = P(E) + P(F)
    We can prove these theorems
        1) for any event E, P(E^c) = 1-P(E)
            It may be easier to calculate it's compliment
            P(E^c) = P(Sample Space) - P(E)
            Compliment is probability of E not happening
            1 = P(SS) = P(EuE^c) = P(E) + P(E^c) = 1
        2) P(EuF) = P(E) + P(F) - P(EnF)    
            Area of both minus whatever overlaps because you counted it twice
            
            
------- February 2nd --------

Random Variable
    X = num of H in 10 flips of a coin
        Probabilistic process
            tossing of a coin 3 times
        Sample space
            all possible outcomes of flipping a coin threee times
            {
            (h,h,h),
            (h,h,t),
            (h,t,h),
            (t,h,h),
            (h,t,t),
            (t,h,t),
            (t,t,h),
            (t,t,t),
            }
        Possible values for X
            {0, 1, 2, 3}
        P(x=1)
            3/8
            
    If outcomes are equally likely
        P(E) = |E|/|SS|
    
    Y = num times it runs corretly before fail
    Takes in the event -> outputs real number
    
    iPod has 100 songs, 10 are beatles
    Probability of first beatles song being played 5th
        Without replacement
        1st not B = 90/100
        2nd not B = 89/99
        3nd not B = 88/98
        4nd not B = 87/97
        5nd not B = 10/96
        multiply these
        P(B on 5th) = 90/100 * 89/99 * 88/98 * 87/97 * 10/96
            = 0.0679
            
    Probability of getting a flush in poker
        1 = 52/52
        2 = 12/51
        3 = 11/50
        4 = 10/49
        5 = 9/48
        
        P(flush) = 1 * 12/51 * 11/50 * 10/49 * 9/48
            = 0.00198
            
    Probability of getting three kings in a hand
        1 = 4/52 
        2 = 3/51
        3 = 2/50
        4 = 48/49
        5 = 47/48
        
        Only for one order!!
        
        count it by combination
        10 = 5C3 = (^5v3)
        (nCk) = n! / k!(n-k)!
        k = number of successes
        
        10 * probability
            
Interpretations of probability
    mathematical construct
    How we interpret it in Real world is not always clear
        relative frequency interpretation
            What is going to happen in the long run
        
------ February 5 ----------

Conditional Probability
    How "B has occured" affexts proability of A
    
    Blood test returns negative
        Probability of disease, given the test
        
    P(A|B) = prob of A given B
        = P(AnB)/P(B)
        
    A has 8 parts - 2 defective
    B has 10 parts - 1 defective
    Chooses defective part
        chance it was made by line A
        
        P(A|D) = P(AnD)/P(D)
            = (2/18)/(3/18)
            = 2/3
            
Multiplication Rul
    P(AnB) = P(B)*P(A|B)
    
A and B are independent if P(A|B) = P(A) and vice versa
Otherwise it is dependent

Multiplication Rule for Independent events 
    P(AnB)=P(A)P(B)
    
    P('2 fours') = P(4)P(4) = (1/6)(1/6) = 1/36
    
    
1200 people
250 seniors
150 in Math
40 seniors in math

If student chosen is senior
Prop of them taking math

P(M|S) = P(MnS)/P(S) = (40/1200)/(250/1200) = 4/25


------- Feb 7 -------

Bayes Theorem
    P(A|B) = P(B|A)P(A)/P(B)
    
    P(A|B) = P(AnB)/P(B)
    P(AnB) = P(B|A)P(A)
    
B = BnA1uBnA2uBnA3
and A1nA2nA3 = 0
and A1uA2uA3 = sample space

P(B) = P(BnA1)+P(BnA2)+P(BnA3)
P(B) = P(B|A1)P(A1)+P(B|A2)P(A2)+P(B|A3)P(A3)
We can do this as long as there is no overlap and the union between A's covers SS


3 different email accounts
1 - 70% - 1% spam
2 - 20% - 2% spam
3 - 10% - 5% spam

P(A1) = 0.7
P(A2) = 0.2
P(A3) = 0.1 

P(S|A1) = 0.01
P(S|A2) = 0.02  
P(S|A3) = 0.05

P(S) ??? = (0.7*0.01)+(0.2*0.02)+(0.1*0.05) = 0.016

P(A1|S) = P(S|A1)P(A1)/P(S)
    = (0.01*0.7)/0.016 = 0.4375
    
    
Random Variables
    Random variable that maps events to real numbers
    1 X - num of H in n flips
    2 num times door opens
    X = random varibale
    x = spcific output 
    
--------- Feb 9 ---------

Probability Density/Distribution functions
    (pdf)
    If random variable X is discrete, the pdf answers questiions like
        P(X=x) called probability mass function
    If X is continuous, then __P(X=x)__ = 0 for ALL x
        The distribution function is called probability density function
        In this case, the pdf provides answers to P(a < X < b)
        
    Properties of pdf - for f(x) to be a legitimate pdf
        1. f(x) >= 0
        2. sum f(x) = sum P(X=x) = 1
            x = mass
        3. integral f(x)dx = 1
            x = density
    
    Discrete random variables
        the pdf, or pmf of a discrete X
        
        X is num of computers used during lunch hour
        
        P(X <= 2) = P(X=0) + P(X=1) + P(X=2)
        P(X >= 3) = 
        P(X=3 u X=2) = P(X=3) + P(X=2)
        
    Bernoulli Distribution
    BRV any random variable whose only possible values are 0 or 1
        this is a discrete random variable
        the distribution is spcified by a single parameter
        p = prob of success
        0 = failiure, 1 = success 
        P(X=x) = where x = 0 or 1
        
        
--------- Feb 12 ---------------
EXAM on the 21
    UNIT 1
    Basic Probability
    Discrete random variable
        
        
        Previous day continued
        Distribution is spcified by a single parameter
        For an output of only 0 or 1
        p = prob of success
            P(X=x) => 
                P(X=1) = p
                P(X=0) = 1-p
            P(f) = (1-p)^(1-x) * p^x
            
        Bernoulli variables posibilities with 1 or 0 output
            coin flip
            Pass fail class
            Spam/not spam
            hotdog/not hotdog
            
            X is a BRN with the probability p
            X~Bern(p)
            
        X = number of heads/success
            P(X=2)?
                HHTT
                (1/2)(1/2)(1/2)(1/2)
                4C2 = 4! / 2!(4-2)!
                = (1/2)^4 * 4C2
            
            P(X=3)?
                HHHT
                (1/2)(1/2)(1/2)(1/2)
                = 1/16
                = 1/16 * 4 (for the number of variations with 3 heads)
                = 4/16 = 1/4
                
            P(X=x) = (nCx) * P^x * (1-p)^(1-x)
            n = num of trials
            x = num of success'
            
            xe = {0,1,2,...,n}
            
    Geometric distribution
        Kidney transplant suitable match = 0.1
        Prob first donor tested is first matching donor
            First? 0.1
            2nd? 0.9 * 0.1
            3rd? 0.9^2 * 0.1
            
        P(X=x) = (1-p)^x * p
        x = num of faliures before first success
        
        X~G(p)
            
            
    Negative Binomial Distribution
        Number of faliures before the second success
        
        pmf = 
            P(X=x) = (x+r-1 C r-1) (p)^r (1-p)^x
        
        let r = 4
        
        P(X=x)~NB(r,p)
        
        5 people to participate, p = 0.2 that they say yes
        Prob(15 people are asked before 5 are found)
        
        P(X=10) = (14C4) (0.2^5) (0.8^10)
        = (14! / 4!(14-4)!) * (0.00032) * (0.8^10)
        = 1001 * 0.00032 * (0.8^10)
        = 0.034
         
---------- Feb 14th -----------

in R dbinom() = density binomial distribution
        
        Binomial distribution => X ~ Bin(50,0.3) 
        
    The poisson distribution
    describes total number of events that happen in certain time period
    # vehicles arriving in parking lot in one week
    # cookies sold in bake sale
    
    pmf for poisson?
    P(X=x) = (e^-lambda * lambda^x)/x! 
        lambda > 0 and is what happens on average
        X~P(lambda)
        
    lambda = 4.5
    P(X=5) = (e^-4.5 * 4.5^5)/5! = 0.1708...
    
    R command: dpois(x, lambda)
    
        
        
--------- Feb 16 ---------

    Continuous distributions
        Random variableX is continuous P(X=x) = 0 for any x because there are infinite possibilities
        Depth of a lake at any given point
        
        Graph of density function
            curve is f(x) to find area under curve between aand b
            Get an integral from a to b of density function
        P(a<X<b) = integral of f(x)dx
        
        Consider a reference line connectingvalve stem on a tire tot the center point
        
    Uniform Distribution
        PDF = f(x) = {1/b-a, x[a,b]    -     0, 0}
        
        
        
        
        
        
        
        
        
        
        
        
        
    
            
